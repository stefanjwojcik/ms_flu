cchidist <- rep(NA, J)
if (!is.na(subsetrow[1])) {
obj <- obj[subsetrowt, ]
}
if (!is.na(subsetcol[1])) {
obj <- obj[, subsetcolt]
}
if (!is.na(suprow[1])) {
if (is.na(supcol[1])) {
P.stemp <- matrix(as.matrix(obj[suprow, ]), nrow = length(suprow))
}
else {
P.stemp <- matrix(as.matrix(obj[suprow, -supcol]),
nrow = length(suprow))
}
P.stemp <- P.stemp/apply(P.stemp, 1, sum)
P.stemp <- t((t(P.stemp) - cm)/sqrt(cm))
rschidist <- sqrt(apply(P.stemp^2, 1, sum))
rchidist[-suprow] <- rachidist
rchidist[suprow] <- rschidist
}
else rchidist <- rachidist
if (!is.na(supcol[1])) {
if (is.na(suprow[1])) {
P.stemp <- as.matrix(obj[, supcol])
}
else {
P.stemp <- as.matrix(obj[-suprow, supcol])
}
P.stemp <- t(t(P.stemp)/apply(P.stemp, 2, sum))
P.stemp <- (P.stemp - rm)/sqrt(rm)
cschidist <- sqrt(apply(P.stemp^2, 2, sum))
cchidist[-supcol] <- cachidist
cchidist[supcol] <- cschidist
}
else {
cchidist <- cachidist
}
phi <- as.matrix(u[, 1:nd])/sqrt(rm)
gam <- as.matrix(v[, 1:nd])/sqrt(cm)
if (!is.na(suprow[1])) {
cs <- cm
gam.00 <- gam
base2 <- SR/matrix(rs.sum, nrow = nrow(SR), ncol = ncol(SR))
base2 <- t(base2)
cs.0 <- matrix(cs, nrow = nrow(base2), ncol = ncol(base2))
svphi <- matrix(sv[1:nd], nrow = length(suprow), ncol = nd,
byrow = TRUE)
base2 <- base2 - cs.0
phi2 <- (t(as.matrix(base2)) %*% gam.00)/svphi
phi3 <- matrix(NA, ncol = nd, nrow = I)
phi3[suprow, ] <- phi2
phi3[-suprow, ] <- phi
rm0 <- rep(NA, I)
rm0[-suprow] <- rm
P.star <- SR/n
rm0[suprow] <- NA
rin0 <- rep(NA, I)
rin0[-suprow] <- rin
rin <- rin0
rm.old <- rm
rm <- rm0
}
if (!is.na(supcol[1])) {
if (!is.na(suprow[1])) {
rs <- rm.old
}
else {
rs <- rm
}
phi.00 <- phi
base2 <- SC/matrix(cs.sum, nrow = nrow(SC), ncol = ncol(SC),
byrow = TRUE)
rs.0 <- matrix(rs, nrow = nrow(base2), ncol = ncol(base2))
svgam <- matrix(sv[1:nd], nrow = length(supcol), ncol = nd,
byrow = TRUE)
base2 <- base2 - rs.0
gam2 <- (as.matrix(t(base2)) %*% phi.00)/svgam
gam3 <- matrix(NA, ncol = nd, nrow = J)
gam3[supcol, ] <- gam2
gam3[-supcol, ] <- gam
cm0 <- rep(NA, J)
cm0[-supcol] <- cm
P.star <- SC/n
cm0[supcol] <- NA
cin0 <- rep(NA, J)
cin0[-supcol] <- cin
cin <- cin0
cm <- cm0
}
if (exists("phi3")) {
phi <- phi3
}
if (exists("gam3")) {
gam <- gam3
}
dims <- paste0("Dim", seq_along(sv))[1:nd]
dimnames(phi) <- list(rn, dims)
dimnames(gam) <- list(cn, dims)
ca.output <- list(sv = sv, nd = nd0, rownames = rn, rowmass = rm,
rowdist = rchidist, rowinertia = rin, rowcoord = phi,
rowsup = suprow, colnames = cn, colmass = cm, coldist = cchidist,
colinertia = cin, colcoord = gam, colsup = supcol, N = N,
call = match.call())
class(ca.output) <- "ca"
return(ca.output)
}
HairEyeColor
?ca
margin.table(HairEyeColor, 1:2)
?margin.table
25*25
haireye <- margin.table(HairEyeColor, 1:2)
haireye
class(haireye)
cav2(haireye)
obj <- haireye
obj
nd0 <- nd
nd = NA; suprow = NA; supcol = NA; subsetrow = NA;
subsetcol = NA
bd
nd
nd0 <- nd
I <- dim(obj)[1]
J <- dim(obj)[2]
rn <- dimnames(obj)[[1]]
cn <- dimnames(obj)[[2]]
N <- matrix(as.matrix(obj), nrow = I, ncol = J)
N
obj
Ntemp <- N
NtempC <- NtempR <- N
suprow <- sort(suprow)
N
Ntemp
NtempR
suprow <- sort(suprow)
supcol <- sort(supcol)
suprow
supcol
!is.na(supcol[1])
subsetcol
subsetcolt
dim.N
dim(N)
dim.N <- dim(N)
dim
dim.N
N00 <- N
dim.N[2] > dim.N[1]
nd.max <- min(dim.N) - 1
nd.max
nd
md.max
nd.max
nd <- nd.max
n <- sum(N)
P <- N/n
rm <- apply(P, 1, sum)
cm <- apply(P, 2, sum)
eP <- rm %*% t(cm)
eN <- eP * n
S <- (P - eP)/sqrt(eP)
4*17.7
4*17.5
70*4
100/(100+180)
7000*.357
5320-2499
2*25
25*25
5275/48
720/60
949*4
library(ggplot2)
library(stargazer)
library(effects)
library(Zelig)
library(noncensus)
library(texreg)
library(dplyr)
library(tidytext)
library(SnowballC)
library(data.table)
library(irr)
d1 = readRDS("~/Documents/ms_flu/data/main_flu_dat.rds")
mod_names = names(d1)
nice_names = c("A1", "A2", "B1", "B2", "Any.Flu.Term", "Search.Volume",
"Female", "Parent", "Spouse", "Age", "Household.Flu",
"Respondent.Flu", "Spouse.Flu", "Child.Flu", "Primary.User",
"Education", "Race", "Early.Response", "info_source")
names(d1) = nice_names
table(d1$A1, d1$Household.Flu)
d1 %>% group_by(Household.Flu) %>% summarise(mean(A1))
d1 %>% group_by(A1) %>% summarise(mean(Household.Flu))
d1$A2[which(d1$A1==1 & d1$A2==1)] = NA
table(d1$A2, d1$Household.Flu)
d1 %>% group_by(Household.Flu) %>% summarise(mean(A2, na.rm=T))
d1 %>% group_by(A2) %>% summarise(mean(Household.Flu))
tau = readRDS("~/Documents/ms_flu/data/tau.rds")
tau = tau$numer/tau$denom
fixTau = function(yhat, tau){
log( ( (1 - tau) / tau) * (yhat / (1 - yhat) ) )
}
names(d1) = mod_names
ma1 <- zelig(a1~household.flu+volume+female+parent+age, model="relogit", tau=tau, data=d1)
ma2 <- zelig(a1~ch.flu+volume+female+age, model="relogit", tau=tau, data=d1)
ma3 <- zelig(a1~r.flu+volume+female+parent+age, model="relogit", tau=tau, data=d1)
ma4 <- zelig(a1~s.flu+volume+female+age, model="relogit", tau=tau, data=d1) #
texreg(c(ma1, ma2, ma3, ma4))
ma12 <- zelig(a2~household.flu+volume+female+parent+age, model="relogit", tau=tau, data=d1)
ma22 <- zelig(a2~ch.flu+volume+female+age, model="relogit", tau=tau, data=d1)
ma32 <- zelig(a2~r.flu+volume+female+parent+age, model="relogit", tau=tau, data=d1)
ma42 <- zelig(a2~s.flu+volume+female+age, model="relogit", tau=tau, data=d1) #
texreg(c(ma12, ma22, ma32, ma42))
ma5 <- zelig(a1~household.flu+education+race, model="relogit", tau=tau, data=d1)
ma6a <- zelig(household.flu~volume+female+parent+age+early_response, model = "logit", data=d1)
ma6b <- zelig(r.flu~volume+female+parent+age+early_response, model = "logit", data=d1)
ma6c <- zelig(s.flu~volume+female+parent+age+early_response, model = "logit", data=d1)
texreg(c(ma6a, ma6b, ma6c))
ma_healh <- zelig(info_from_provider ~ a1, model = "logit", data=d1)
table(d1$a1, d1$info_from_provider)
names(d1)
ma_healh <- zelig(info_source ~ a1, model = "logit", data=d1)
table(d1$a1, d1$info_source)
summary(d1$volume)
volume <- c(4.852, 6.661)  #from third quartile to first
ma1X <-setx(ma1, volume = volume)  # Simulate quantities of interest
ma1sim <- sim(ma1, x = ma1X)  # Extract expected values from simulations
df = zelig_qi_to_df(ma1sim)
head(df)
dim(df)
?sim
?pnorm
?quantile
quantile(df$expected_value[df$volume==6.661]/df$expected_value[df$volume==4.852], probs=c(.05, .95))
lo_vol = mean(df$expected_value[df$volume==4.852])
hi_vol = mean(df$expected_value[df$volume==6.661])
hi_vol/lo_vol
mean(hi_vol)-mean(lo_vol)
quantile(hi_vol-lo_vol, probs=c(.05, .95))
quantile((hi_vol-lo_vol), probs=c(.05, .95))
install.packages("bigint")
install.packages("int64")
options(digits=99)
options(digits=22)
mean(hi_vol)/mean(lo_vol)
quantile(hi_vol/lo_vol, probs=c(.05, .95))
lo_vol = df$expected_value[df$volume==4.852]
hi_vol = df$expected_value[df$volume==6.661]
mean(hi_vol)/mean(lo_vol)
quantile(hi_vol/lo_vol, probs=c(.05, .95))
mean(hi_vol)-mean(lo_vol)
quantile((hi_vol-lo_vol), probs=c(.05, .95))
?options
options(digits=7)
set.seed(765)
summary(d1$volume)
volume <- c(4.852, 6.661)  #from third quartile to first
ma1X <-setx(ma1, volume = volume)  # Simulate quantities of interest
ma1sim <- sim(ma1, x = ma1X)  # Extract expected values from simulations
df = zelig_qi_to_df(ma1sim)
lo_vol = df$expected_value[df$volume==4.852]
hi_vol = df$expected_value[df$volume==6.661]
mean(hi_vol)/mean(lo_vol)
quantile(hi_vol/lo_vol, probs=c(.05, .95))
mean(hi_vol)-mean(lo_vol)
quantile((hi_vol-lo_vol), probs=c(.05, .95))
median((hi_vol-lo_vol))
summary((hi_vol-lo_vol))
?irlba
library(irlba)
install.packages("irlba")
18*20
df = read.csv("~/Downloads/boa_trs.csv")
head(df$Date)
df$Date = as.Date(as.character(df$Date))
df$Date = as.Date(as.character(df$Date), format = "%m/%d/%y")
head(df$Date)
df$month = month(df$Date)
library(lubridate)
df$month = month(df$Date)
library(dplyr)
df$year = year(df$Date)
df %>% group_by(month, year) %>% summarise(sum(Amount))
this = df %>% group_by(year, month) %>% summarise(sum(Amount))
View(this)
600+1200
qplot(this$`sum(Amount)`)
library(ggplot2)
qplot(this$`sum(Amount)`)
qplot(this$month, this$`sum(Amount)`)
qplot(this$year, this$`sum(Amount)`)
this = df %>% filter(transaction=="debit") %>% group_by(year, month) %>% summarise(sum(Amount))
names(df)
this = df %>% filter(Transaction.Type=="debit") %>% group_by(year, month) %>% summarise(sum(Amount))
this
View(this)
View(this)
View(df)
1500 + 4000
2863+1000
3863 + 350
4213*.15
631.95*2
(4213*2)-1263.9
7162.1 + (1450*2)
(3213*2)-1263.9
5162 +  (1450*2)
(2863*2) - 1263
4463 + (1450*2)
7363 - 1600 - 4000
1763-244
1519-50-60
4463/(4463 + (1450*2))
180/(180+100)
442000*.05
442000*.03
df = read.csv("~/Downloads/boa_trs.csv")
df$month = month(as.Date(as.character(df$Date, format = "%m/%d/%y")))
df$month = month(as.Date(as.character(df$Date), format = "%m/%d/%y"))
df$Date = as.Date(as.character(df$Date), format = "%m/%d/%y")
df$year = year(df$Date)
this = df %>% filter(Transaction.Type=="debit") %>% group_by(year, month) %>% summarise(total = sum(Amount))
this
qplot(data = this, x=month, y=total, col=year)
qplot(data = this, x=month, y=total, col=as.factor(year))
qplot(data = this, x=as.factor(month), y=total, col=as.factor(year))
qplot(data = this, x=as.factor(month), y=total, col=as.factor(year), geom="line")
qplot(data = this, x=as.factor(month), y=total, col=as.factor(year), geom="abline")
qplot(data = this, x=as.factor(month), y=total, col=as.factor(year), geom="point")
qplot(data = this, x=as.factor(month), y=total, col=as.factor(year)) + geom_line()
qplot(data = this, x=as.factor(month), y=total, group=as.factor(year)) + geom_line()
qplot(data = this, x=as.factor(month), y=total, group=as.factor(year), col=as.factor(year)) + geom_line()
3.75*24
.1*1700
setwd("~/Documents/ms_flu/Forecasting")
source("Supp.R")
set.seed(5)
## US Flu Rates
start = 1
State = "US"
Z <- data.frame(read.csv("Data/USFlu.csv" , header = TRUE,stringsAsFactors = FALSE))
Z <- Z[start:nrow(Z),]
Yf <- na.approx((Z$Total))
## Rolling 3 Year Period
T1 = 1
T2 = 104+52
## Lasso (ARGO) with All Queries - Normalize and logit transformed
X_q <- read.csv("Data/logit_national_queries.csv", header = T, stringsAsFactors = F)
# Compute CCF with the Flu series and keep only queries with > 0.5 correlation
cc <- apply(X_q,2, function(x) cor(Yf[1:T2],x[1:T2]))
ind <- which(cc > 0.5)
X_q <- X_q[,ind]
## Lasso with MRP adjusted A1 queries
Xmrp <- data.frame(read.csv("Data/mrp_national_queries.csv" , header = TRUE,stringsAsFactors = FALSE))
# Search Data Process and Merge with Flu Rates (match on existing weeks) (Logit Transformed)
Ymrp <- smoothA1Process("Data/estimates_flu_US_3daywindowV7.csv", State)
Yraw <- smoothA1Process("Data/USRaw.csv", State)
Yr <- read.csv("Data/logit_raw_all.csv",header = F, stringsAsFactors = F)
Yr <- Yr$V1
Ym <- na.approx(log(Ymrp[,3]))
# Train
# Regress at Lag
lag_m = 0  # US
lag_r = 0 # US
season = 52 # US
## Create the Data Frames for all the different Signals and Methods
# Adjust for Lags (Not Relevant Here)
if(lag_m==lag_r) {
Ysub_mrp <- data.frame(cbind(Yf[(lag_m+1):length(Yf)], Ym[1:(length(Ym)-lag_m)])) # MRP
Ysub_raw <- data.frame(cbind(Yf[(lag_r+1):length(Yf)], Yr[1:(length(Yr)-lag_r)])) # A1
Ysub_all <- data.frame(cbind(Yf[(lag_r+1):length(Yf)], Yr[1:(length(Yr)-lag_r)], Ym[1:(length(Ym)-lag_m)])) # Raw
Ysub_X <-  data.frame(cbind(Yf[(lag_r+1):length(Yf)], X_q)) # Raw
}
## Auto-Arima
## Auto-Arima
## Find the best model for SARIMA-HIST
require(forecast)
mdl_hist_auto <- auto.arima(ts(Ysub_mrp[T1:T2,1],frequency=season),stationary = T, approximation=F, parallel = T,stepwise = F, seasonal = T, ic = "aic",allowdrift = F, allowmean = F, max.D = 1)
print(mdl_hist_auto)
mdl_h_auto <- list()
mdl_params <- arimaorder(mdl_hist_auto)
print(mdl_params)
mdl_h_auto$p <- mdl_params[1]
mdl_h_auto$d <- mdl_params[2]
mdl_h_auto$q <- mdl_params[3]
if(length(mdl_params)>3) {
mdl_h_auto$sp <- mdl_params[4]
mdl_h_auto$sd <- mdl_params[5]
mdl_h_auto$sq <- mdl_params[6]
} else {
mdl_h_auto$sp <- 0
mdl_h_auto$sd <- 0 #mdl_params[5]
mdl_h_auto$sq <- 0
}
## Find the best model for SARIMA-MRP
mdl_mrp_auto <- auto.arima(ts(Ysub_mrp[T1:T2,1],frequency=season) ,stationary = T, approximation=F, xreg = Ysub_mrp[T1:T2,2],parallel = T,stepwise = F, seasonal = T, ic = "aic",allowdrift = F,allowmean = F, max.D=1)
print(mdl_mrp_auto)
mdl_m_auto <- list()
mdl_params <- arimaorder(mdl_mrp_auto)
print(mdl_params)
mdl_m_auto$p <- mdl_params[1]
mdl_m_auto$d <- mdl_params[2]
mdl_m_auto$q <- mdl_params[3]
if(length(mdl_params)>3) {
mdl_m_auto$sp <- mdl_params[4]
mdl_m_auto$sd <- mdl_params[5]
mdl_m_auto$sq <- mdl_params[6]
}else {
mdl_m_auto$sp <- 0
mdl_m_auto$sd <- 0
mdl_m_auto$sq <- 0
}
## Find the best model for SARIMA-A1
mdl_raw_auto <- auto.arima(ts(Ysub_raw[T1:T2,1],frequency=season) , stationary = T, approximation=F, xreg = Ysub_raw[T1:T2,2], parallel = T, stepwise = F, seasonal = T, ic = "aic",allowdrift = F, allowmean = F, max.D = 1)
print(mdl_raw_auto)
mdl_r_auto <- list()
mdl_params <- arimaorder(mdl_raw_auto)
print(mdl_params)
mdl_r_auto$p <- mdl_params[1]
mdl_r_auto$d <- mdl_params[2]
mdl_r_auto$q <- mdl_params[3]
if(length(mdl_params)>3) {
mdl_r_auto$sp <- mdl_params[4]
mdl_r_auto$sd <- mdl_params[5]
mdl_r_auto$sq <- mdl_params[6]
}else {
mdl_r_auto$sp <- 0
mdl_r_auto$sd <- 0 #mdl_params[5]
mdl_r_auto$sq <- 0
}
## Argo Model (All Queries)
require(xts)
require(argo)
timef <- as.Date(paste("0", Z$Week, sep="-"), format= "%w-%Y-%W")
timef[157] <- timef[156]
dates <- as.Date(timef,format="%Y-%m-%d")
Zflu <- xts(Ysub_X[,1], dates)
names(Zflu) <- "ILI"
Xog <- xts(Ysub_X[,2:ncol(Ysub_X)], dates)
Xmrp <- xts(sqrt(Xmrp[1:279,3:ncol(Xmrp)]), dates)
mdl_argo_hist <- argo(Zflu, exogen = NULL, N_lag = 1:52, N_training = T2-53, alpha = 1, use_all_previous = F)
mdl_argo_all <- argo(Zflu, exogen = Xog, N_lag = 1:52, N_training = T2-53, alpha = 1, use_all_previous = F)
mdl_argo_mrp <- argo(Zflu, exogen = Xmrp, N_lag = 1:52, N_training = T2-53, alpha = 1, use_all_previous = F)
# Compute Prediction Errors (Auto Arima)
method = "ML"
mdlx <- mdl_m_auto
mdlh <- mdl_h_auto
mdlr <- mdl_r_auto
rmse1step_m_auto <- nStepAheadAuto(Ysub = Ysub_mrp, mdlx, mdlh, ahead=1, method = method, season=season, T2=T2,incl_mean = F, incl_mean_hist = F)
rmse2step_m_auto <- nStepAheadAuto(Ysub = Ysub_mrp, mdlx, mdlh, ahead=2, method = method, season=season, T2=T2,incl_mean = F, incl_mean_hist = F)
rmse1step_r_auto <- nStepAheadAuto(Ysub = Ysub_raw, mdlr, mdlh, ahead=1, method = method,season=season, T2=T2, incl_mean = F, incl_mean_hist = F)
rmse2step_r_auto <- nStepAheadAuto(Ysub = Ysub_raw, mdlr, mdlh, ahead=2, method = method,season=season, T2=T2, incl_mean = F, incl_mean_hist = F)
## Compute RMSE
y_actual <- Ysub_X[(T2+1):nrow(Ysub_X),1]
rmse_r_1step_auto <- sqrt(mean((y_actual-rmse1step_r_auto[,2])^2))
rmse_r_2step_auto <- sqrt(mean((y_actual[2:length(y_actual)]-rmse2step_r_auto[,2])^2))
rmse_m_1step_auto <- sqrt(mean((y_actual-rmse1step_m_auto[,2])^2))
rmse_m_2step_auto <- sqrt(mean((y_actual[2:length(y_actual)]-rmse2step_m_auto[,2])^2))
rmse_h_1step_auto <- sqrt(mean((y_actual[1:length(y_actual)]-rmse1step_m_auto[,3])^2))
rmse_h_2step_auto <- sqrt(mean((y_actual[2:length(y_actual)]-rmse2step_m_auto[,3])^2))
pred_argo_hist <- na.omit(as.numeric(mdl_argo_hist$pred))
pred_argo_all <- na.omit(as.numeric(mdl_argo_all$pred))
pred_argo_mrp <- na.omit(as.numeric(mdl_argo_mrp$pred))
mrp_acc <- accuracy(rmse1step_m_auto[,2],y_actual) #SARIMA-MRP
hist_acc <- accuracy(rmse1step_m_auto[,3],y_actual) # SARIMA-HIST
raw_acc <- accuracy(rmse1step_r_auto[,2],y_actual) # SARIMA-A1
argo_hist_acc <- accuracy(pred_argo_hist,y_actual) # ARGO-HIST
argo_a1_acc <- accuracy(pred_argo_all,y_actual) # ARGO-A1
mrp_acc
hist_acc
raw_acc
argo_hist_acc
mrp_acc_2 <- accuracy(rmse2step_m_auto[,2],y_actual[2:length(y_actual)]) #SARIMA-MRP
raw_acc_2 <- accuracy(rmse2step_r_auto[,2],y_actual[2:length(y_actual)]) #SARIMA-A1
hist_acc_2 <- accuracy(rmse2step_r_auto[,3],y_actual[2:length(y_actual)]) # SARIMA-HIST
mrp_acc_2
hist_acc_2
mrp_acc_2
raw_acc_2
hist_acc_2
cor(Yraw, Z)
X
Z
YF
Yf
length(Yf)
length(Yraw)
length(Yr)
cor(Yr, Yf)
cor(Ymrp, Yf)
cor(Ym, Yf)
head(Ymrp)
head(Ymrp[Ymrp$year>=2016])
head(Ymrp[Ymrp$year>=2016, ])
cor(Ymrp$US[Ymrp$year>=2016], Yraw$US[Yraw$year>=2016])
cor(Ymrp$US[Ymrp$year>=2016], Yraw$US[Yraw$year>=2016])
head(Z)
Z[Z$Week>"2016-01-01"]
Z[Z$Week>"2016-01-01", ]
length(Z$Total[Z$Week>"2016-01-01"])
length(Yraw$US[Yraw$year>=2016])
Yraw$US[-71:-1]
Yraw$US[-1]
tail(Yraw$US, 71)
cor(tail(Yr, 71), tail(Yf, 71))
cor(tail(Ym, 71), tail(Yf, 71))
Ysub_mrp
install.packages("forecast")
install.packages("forecast")
